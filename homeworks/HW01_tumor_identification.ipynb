{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Finetuning CNNs on medical image data\n",
        "\n",
        "The objective of this homework is to use deep learning to recognize tumors in tissue image. We will use the [PCAM](https://github.com/basveeling/pcam) dataset consisting of \"327.680 color images (96 x 96px) extracted from histopathologic scans of lymph node sections\".\n",
        "\n",
        "**Note:** This homework will require intensive computations. It is thus preferable to use GPUs, for example with Google Colab (free access to GPUs)."
      ],
      "metadata": {
        "id": "FkPRHgzwqQs2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import models,transforms,datasets\n",
        "import time\n",
        "\n",
        "!pip install --quiet --upgrade \"git+https://gitlab.com/robindar/dl-scaman_checker.git\"\n",
        "from dl_scaman_checker import HW01\n",
        "HW01.check_install(requires=\"0.7.1\")"
      ],
      "metadata": {
        "id": "jhu5KXZDNvN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Version v0.7.1 or above of this module is required to bypass an error in torchvision's dataset download.\n",
        "If the module version does not update when you re-run the previous cell, restart the Kernel of the notebook.\n",
        "If you get an error on this cell, it is probably because the module did not update: restart your notebook Kernel and try again.\n",
        "\n",
        "Check if GPU is available and if not change the [runtime](https://jovianlin.io/pytorch-with-gpu-in-google-colab/)."
      ],
      "metadata": {
        "id": "Ipk8fYKiOlPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Using gpu: %s ' % torch.cuda.is_available())"
      ],
      "metadata": {
        "id": "2QS9uVYCOE1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing\n",
        "\n",
        "First, download the PCAM dataset using torchvision (see [documentation](https://pytorch.org/vision/stable/generated/torchvision.datasets.PCAM.html#torchvision.datasets.PCAM)). To keep computation times low, we will use the validation set (parameter `split='val'`) as train set (variable name `data_train`), and the test set (parameter `split='test'`) as test (variable name `data_test`). Plot the first 5 images of the train set corresponding to a tumor and the 5 first corresponding to healthy tissue. Can you see a difference?\n",
        "\n",
        "**Note:** If you get an error with the function provided by torchvision to download PCAM, please use `HW1.PCAM(...)` instead of `datasets.PCAM(...)`. This will download the dataset from another source, but will be slower (approx. 10 minutes)."
      ],
      "metadata": {
        "id": "CeYJp9DdsAGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# YOUR CODE HERE\n",
        "#"
      ],
      "metadata": {
        "id": "wI-lAkpFOAdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use `data_train.transform` and `data_test.transform` (see the [documentation](https://pytorch.org/vision/0.9/transforms.html)) to turn the images into tensors (of shape (3,96,96)) and normalize them using `transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])`, and verify that your data has the correct shape. How many elements are in your train and test sets?"
      ],
      "metadata": {
        "id": "OH8VdXRXwVd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# YOUR CODE HERE\n",
        "#"
      ],
      "metadata": {
        "id": "1qYrKnqCwkEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now create a train and a test dataloader with a batch size of 64, and a random permutation for the train dataloader (with `shuffle=True`). How many mini-batches do you have?"
      ],
      "metadata": {
        "id": "dUf-f5ervUtH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# YOUR CODE HERE\n",
        "#"
      ],
      "metadata": {
        "id": "FQTgYsi6PINx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and testing loop\n",
        "\n",
        "Write a function `train_model(model, dataloader, epochs)` that performs `epochs` training epochs using the Adam optimizer (with learning rate $10^{-3}$ and a weight decay of $10^{-1}$) on the cross entropy loss (using `nn.CrossEntropyLoss()`) for the model and data provided as input. **Note:** Remember to set the model to training mode using `model.train()`, and put the model and tensors on the correct device (CPU or GPU) by using `x.to(device)`. Plot the loss and accuracy of the model over the train set at each epoch."
      ],
      "metadata": {
        "id": "fMkGVXP83CvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# YOUR CODE HERE\n",
        "#"
      ],
      "metadata": {
        "id": "gTv9FC5tVUi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now write a function `test_model(model,dataloader)` that plots the loss and accuracy of the model on the whole dataset."
      ],
      "metadata": {
        "id": "w0MkABVu6Cjw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# YOUR CODE HERE\n",
        "#"
      ],
      "metadata": {
        "id": "Hz1sbJrO6pwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training a linear model\n",
        "\n",
        "We now test a baseline model on our classification task: a simple linear model. Create a model using `nn.Sequential` that takes images, flatten them into vectors, and then compute a linear model out of it. The output should be 2-dimensional (to match our 2 classes). Then, train it for 2 epochs and test it on the test dataset."
      ],
      "metadata": {
        "id": "TQR5VTbk73b7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#\n",
        "# YOUR CODE HERE\n",
        "#"
      ],
      "metadata": {
        "id": "lm9fxxiugL8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuning a CNN model\n",
        "\n",
        "We are now going to fine-tune a VGG model trained on [ImageNet](http://www.image-net.org/) (1.2M training images). The torchvision module comes with a zoo of pretrained popular CNN architectures. When called the first time, if `pretrained=True` the model is fetched over the internet and downloaded to `~/.torch/models`. For next calls, the model will be directly read from there.\n",
        "\n",
        "First, load the VGG model using `models.vgg16(weights='DEFAULT')` and print it to see its architecture."
      ],
      "metadata": {
        "id": "3N2XfzIb9p0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# YOUR CODE HERE\n",
        "#"
      ],
      "metadata": {
        "id": "0ZRJB7tMPVVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the model is divided into two part: a **feature** section mainly made of convolutions and pooling layers, and a **classifier** part made of an MLP. We'll learn about what these different blocks do later in the course. For now, it's enough to know that:\n",
        "\n",
        "- Convolution layers are for finding small to medium size patterns in images -- analyzing the images locally\n",
        "- Dense (fully connected) layers are for combining patterns across an image -- analyzing the images globally\n",
        "- Pooling layers downsample -- in order to reduce image size and to improve invariance of learned features\n",
        "\n",
        "The idea of fine-tuning is that the features computed by VGG for Imagenet may be also good for other applications (e.g. for medical images). Replace the last layer of the `model_vgg.classifier` by a new linear layer that outputs 2 values (one for each class), and **freeze** all the other parameters of the VGG model by using `parameter.requires_grad=False` on all the parameters of the model except for the last layer."
      ],
      "metadata": {
        "id": "DWkUYpQ4-9xM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# YOUR CODE HERE\n",
        "#"
      ],
      "metadata": {
        "id": "b1EXdYAMPiwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now fine-tune the model by performing 2 epochs of training."
      ],
      "metadata": {
        "id": "6a6s9wGiBb0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#\n",
        "# YOUR CODE HERE\n",
        "#"
      ],
      "metadata": {
        "id": "1bJkGesgVWOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Speeding-up training by precomputing features\n",
        "\n",
        "We are wasting a lot of time computing over and over the same quantities. Indeed, the first part of the VGG model (called `features` and made of convolutional layers) is frozen and never updated. Hence, we can precompute for each image in the dataset, the output of these convolutional layers as these outputs will always be the same during your training process.\n",
        "\n",
        "Write a function `precompute_model(model, dataloader)` that takes a model and a dataloader as input, and returns a dataset containing the outputs of the model as input using `torch.utils.data.TensorData`."
      ],
      "metadata": {
        "id": "vqWOeWXlCWve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# YOUR CODE HERE\n",
        "#"
      ],
      "metadata": {
        "id": "ncPq4PiWiWIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use `precompute_model` to create a DataLoader for the train and test dataset with precomputed VGG features."
      ],
      "metadata": {
        "id": "cNJSFAz1GQhP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#\n",
        "# YOUR CODE HERE\n",
        "#"
      ],
      "metadata": {
        "id": "9Db9gYZNm2SD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, train a linear model on the new precomputed features for 10 epochs. Is the model better?"
      ],
      "metadata": {
        "id": "JZBGKjALGtzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#\n",
        "# YOUR CODE HERE\n",
        "#"
      ],
      "metadata": {
        "id": "gYmrTkCloO-J"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}